<!doctype html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1">

        <meta name="description" content="">
        <meta name="author" content="">

        <title>OCR - M1 Project</title>

        <!-- CSS FILES -->
        <link rel="preconnect" href="https://fonts.googleapis.com">

        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>

        <link href="https://fonts.googleapis.com/css2?family=Inter:wght@100;300;400;700;900&display=swap" rel="stylesheet">

        <link href="css/bootstrap.min.css" rel="stylesheet">
        <link href="css/bootstrap-icons.css" rel="stylesheet">

        <link rel="stylesheet" href="css/slick.css"/>

        <link href="css/tooplate-little-fashion.css" rel="stylesheet">
        
    </head>
    
    <body>

        <section class="preloader">
            <div class="spinner">
                <span class="sk-inner-circle"></span>
            </div>
        </section>
    
        <main>

            <nav class="navbar navbar-expand-lg">
                <div class="container">
                    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
                        <span class="navbar-toggler-icon"></span>
                    </button>

                    <a class="navbar-brand" href="index.html">
                        <strong><span>M1</span> Project</strong>
                    </a>

                    <div class="collapse navbar-collapse" id="navbarNav">
                        <ul class="navbar-nav mx-auto">
                            <li class="nav-item">
                                <a class="nav-link" href="index.html">Home</a>
                            </li>

                            <li class="nav-item">
                                <a class="nav-link" href="federated-learning.html">Federated Learning</a>
                            </li>

                            <li class="nav-item">
                                <a class="nav-link" href="OCR.html">OCR</a>
                            </li>

                            <li class="nav-item">
                                <a class="nav-link" href="example.html">Example</a>
                            </li>

                        </ul>
                    </div>
                </div>
            </nav>

            <header class="site-header section-padding-img site-header-image">
                <div class="container">
                    <div class="row">

                        <div class="col-lg-6 col-12 header-info">
                            <h1>
                                <span class="d-block text-primary">OCR</span>
                                <h2 class="d-block text-dark"> <span>O</span>ptical <span>C</span>haracter <span>R</span>ecognition</h2>
                            </h1>
                        </div>
                    </div>
                </div>

                <img src="images\OCR\Technoglogie-OCR-pour-applications-mobiles.png" class="header-image img-fluid" alt="" style="width: 35%; height: auto;">
            </header>


            <section id="link" class="front-product">
                <div class="container-fluid p-0">
                    <div class="row align-items-center">

                        <div class="col-lg-6 col-12">
                            <img src="images\OCR\a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way.webp" class="img-fluid" alt="">
                        </div>

                        <div class="col-lg-6 col-12">
                            <div class="px-5 py-5 py-lg-0">
                                
                                <h2 class="mb-4"><span>CNN</span> : <span>C</span>onvolutional <span>N</span>eural <span>N</span>etwork</h2>

                                <p class="lead mb-4">To recognize characters (numbers and letters) we will use a technology called CNN (convolutional neural network).</p>

                                <p class="lead mb-4">A CNN, or Convolutional Neural Network, is a type of artificial neural network designed for image recognition and processing tasks. It works by applying a series of filters, or "convolutions," to the input image, extracting features at different spatial locations. Through layers of convolutions followed by pooling and fully connected layers, CNNs can recognize patterns and objects within images with high accuracy, making them essential in tasks like facial recognition, object detection, and image analysis.</p>

                            </div>
                        </div>

                    </div>
                </div>
            </section>

            <section id="link" class="front-product">
                <div class="container-fluid p-0">
                    <div class="row align-items-center">

                        <div class="col-lg-6 col-12">
                            <img src="images\OCR\Transfer+learning.png" class="img-fluid" alt="">
                        </div>

                        <div class="col-lg-6 col-12">
                            <div class="px-5 py-5 py-lg-0">
                                <h2 class="mb-4"><span>Transfer</span> Learning</h2>

                                <p class="lead mb-4">Given that training a high-performance CNN (with a large number of layers) requires considerable computing power, we opted for transfer learning. But what is transfer learning? </p>

                                <p class="lead mb-4">Transfer learning is a machine learning technique where a pre-trained model is used as a starting point for a new task, typically with a different dataset. It involves fine-tuning the pre-trained model's parameters on the new data, leveraging the knowledge it gained from its original task to improve performance on the new task. This approach is particularly useful when labeled data is limited or when training a model from scratch would be computationally expensive, allowing for faster and more efficient development of models for various tasks.</p>

                            </div>
                        </div>

                    </div>
                </div>
            </section>

            <section id="link" class="front-product">
                <div class="container-fluid p-0">
                    <div class="row align-items-center">

                        <div class="col-lg-6 col-12">
                            <img src="images\OCR\imagenet_banner.jpeg" class="img-fluid" alt="">
                        </div>

                        <div class="col-lg-6 col-12">
                            <div class="px-5 py-5 py-lg-0">
                                <h2 class="mb-4"><span>VGG16</span></h2>

                                <p class="lead mb-4">In our case, we'll use the VGG16 model for transfer learning. The VGG-16 model is a convolutional neural network (CNN) architecture that was proposed by the Visual Geometry Group (VGG) at the University of Oxford. It is characterized by its depth, consisting of 16 layers, including 13 convolutional layers and 3 fully connected layers. VGG-16 is renowned for its simplicity and effectiveness, as well as its ability to achieve strong performance on various computer vision tasks, including image classification and object recognition. The model’s architecture features a stack of convolutional layers followed by max-pooling layers, with progressively increasing depth. This design enables the model to learn intricate hierarchical representations of visual features, leading to robust and accurate predictions. Despite its simplicity compared to more recent architectures, VGG-16 remains a popular choice for many deep learning applications due to its versatility and excellent performance.

                                    The ImageNet Large Scale Visual Recognition Challenge (ILSVRC) is an annual competition in computer vision where teams tackle tasks including object localization and image classification. VGG16, proposed by Karen Simonyan and Andrew Zisserman in 2014, achieved top ranks in both tasks, detecting objects from 200 classes and classifying images into 1000 categories.</p>

                            </div>
                        </div>

                    </div>
                </div>
            </section>



            

        </main>

        <footer class="site-footer">
            <div class="container">
                <div class="row">

                    <div class="col-lg-3 col-10 me-auto mb-4">
                        <h4 class="text-white mb-3"><a href="index.html">M1</a> Project</h4>
                        <p class="copyright-text text-muted mt-lg-5 mb-4 mb-lg-0">Copyright © 2024 <strong>M1 - Project</strong></p>
                        <br>
                        <p class="copyright-text">Designed by <a href="https://www.tooplate.com/" target="_blank">Antoine & Thomas</a></p>
                    </div>
                </div>
            </div>
        </footer>

        <!-- JAVASCRIPT FILES -->
        <script src="js/jquery.min.js"></script>
        <script src="js/bootstrap.bundle.min.js"></script>
        <script src="js/Headroom.js"></script>
        <script src="js/jQuery.headroom.js"></script>
        <script src="js/slick.min.js"></script>
        <script src="js/custom.js"></script>

    </body>
</html>
